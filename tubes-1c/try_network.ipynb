{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "  #konstruktor\n",
    "  def __init__(self, n_inputs, n_hidden, n_outputs=3):\n",
    "    self.n_inputs = n_inputs\n",
    "    self.n_hidden = n_hidden\n",
    "    self.n_outputs = n_outputs\n",
    "    \n",
    "    self.weights_ItoH = np.random.uniform(-1, 1, (n_inputs, n_hidden))\n",
    "    self.weights_HtoO = np.random.uniform(-1, 1, (n_hidden, n_outputs))\n",
    "    \n",
    "    self.dweights_ItoH = np.zeros((n_inputs, n_hidden))\n",
    "    self.dweights_HtoO = np.zeros((n_hidden, n_outputs))\n",
    "    \n",
    "    self.pre_activation_H = np.zeros(n_hidden)\n",
    "    self.post_activation_H = np.zeros(n_hidden)\n",
    "    \n",
    "    self.pre_activation_O = np.zeros(n_outputs)\n",
    "    self.post_activation_O = np.zeros(n_outputs)\n",
    "  \n",
    "  # Calculate net for an input\n",
    "  def calculate_net_ItoH(self, sample, node):\n",
    "    return np.dot(self.data[sample,:], self.weights_ItoH[:, node])\n",
    "  # Calculate net for a hidden unit\n",
    "  def calculate_net_HtoO(self, node):\n",
    "    return np.dot(self.post_activation_H, self.weights_HtoO[:, node])\n",
    "\n",
    "  # Neuron activation\n",
    "  def activation(self, x):\n",
    "  \treturn 1.0/(1 + np.exp(-x))\n",
    "  \n",
    "  # Derivation of activation function\n",
    "  def activation_deriv(self, x):\n",
    "    return activation(x) * (1 - activation(x))\n",
    "\n",
    "  def one_hot_encode(self, target):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    new_target = target.reshape(len(target), 1)\n",
    "    target_encode = encoder.fit_transform(new_target)\n",
    "\n",
    "  #fit the network to the data\n",
    "  def fit(self, data, target, epoch_limit=100, mini_batch_limit=10):\n",
    "    self.data = data\n",
    "    self.target = self.one_hot_encode(target)\n",
    "    self.epoch_limit = epoch_limit\n",
    "\n",
    "    len_data = len(data)\n",
    "\n",
    "    for epoch in range(epoch_limit):\n",
    "      \n",
    "      mini_batch_count = 0\n",
    "      for instance in range(3):\n",
    "        # From input layer to hidden layer\n",
    "        \n",
    "        ## iterate every hidden layer to fill the values\n",
    "        for hidden_unit in range(self.n_hidden):\n",
    "          ### calculate the net input\n",
    "          self.pre_activation_H[hidden_unit] = self.calculate_net_ItoH(instance, hidden_unit)\n",
    "          ### calculate the activated value\n",
    "          self.post_activation_H[hidden_unit] = self.activation(self.pre_activation_H[hidden_unit])\n",
    "\n",
    "        # From hidden layer to output layer\n",
    "        for output_unit in range(self.n_outputs):\n",
    "          ### calculate the net input\n",
    "          self.pre_activation_O[output_unit] = self.calculate_net_HtoO(output_unit)\n",
    "          ### calculate the activated value\n",
    "          self.post_activation_O[output_unit] = self.activation(self.pre_activation_O[output_unit])\n",
    "      \n",
    "        #for debug\n",
    "        print('INSTANCE:', instance )\n",
    "        print('WEIGHTS\\n', self.weights_ItoH, '\\n', self.weights_HtoO)\n",
    "        print('OUTPUTS\\n', self.post_activation_H, '\\n', self.post_activation_O)\n",
    "\n",
    "        # Backpropagation\n",
    "        ## if already at minibatch limit or at the last instance, update the weight \n",
    "        if((mini_batch_count == mini_batch_limit) or (instance == len_data - 1)):\n",
    "          mini_batch_count = 0\n",
    "        ## if below minibatch limit, update delta-weight\n",
    "        else:\n",
    "          #update delta-weight from output\n",
    "          \n",
    "          \n",
    "          #update delta-weight from hidden layer\n",
    "          mini_batch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Iris\n",
      "INSTANCE: 0\n",
      "WEIGHTS\n",
      " [[-0.86060379 -0.57263416 -0.23529718  0.56293959]\n",
      " [-0.88530683 -0.75437421 -0.34978178 -0.20817233]\n",
      " [ 0.81519213 -0.20898158  0.01588498  0.7544523 ]\n",
      " [ 0.63130405 -0.64220496 -0.72131018  0.00680023]] \n",
      " [[ 0.91570929  0.81372381  0.40482461]\n",
      " [ 0.8517756  -0.5952462  -0.28610893]\n",
      " [-0.21889323 -0.6185325  -0.88764714]\n",
      " [-0.68850269 -0.48786008  0.38546544]]\n",
      "OUTPUTS\n",
      " [0.00198505 0.00251803 0.07267714 0.9608336 ] \n",
      " [0.33771748 0.37435254 0.57589387]\n",
      "INSTANCE: 1\n",
      "WEIGHTS\n",
      " [[-0.86060379 -0.57263416 -0.23529718  0.56293959]\n",
      " [-0.88530683 -0.75437421 -0.34978178 -0.20817233]\n",
      " [ 0.81519213 -0.20898158  0.01588498  0.7544523 ]\n",
      " [ 0.63130405 -0.64220496 -0.72131018  0.00680023]] \n",
      " [[ 0.91570929  0.81372381  0.40482461]\n",
      " [ 0.8517756  -0.5952462  -0.28610893]\n",
      " [-0.21889323 -0.6185325  -0.88764714]\n",
      " [-0.68850269 -0.48786008  0.38546544]]\n",
      "OUTPUTS\n",
      " [0.00366466 0.00411069 0.08912835 0.9605124 ] \n",
      " [0.33760895 0.37210677 0.57234796]\n",
      "INSTANCE: 2\n",
      "WEIGHTS\n",
      " [[-0.86060379 -0.57263416 -0.23529718  0.56293959]\n",
      " [-0.88530683 -0.75437421 -0.34978178 -0.20817233]\n",
      " [ 0.81519213 -0.20898158  0.01588498  0.7544523 ]\n",
      " [ 0.63130405 -0.64220496 -0.72131018  0.00680023]] \n",
      " [[ 0.91570929  0.81372381  0.40482461]\n",
      " [ 0.8517756  -0.5952462  -0.28610893]\n",
      " [-0.21889323 -0.6185325  -0.88764714]\n",
      " [-0.68850269 -0.48786008  0.38546544]]\n",
      "OUTPUTS\n",
      " [0.00336214 0.00404792 0.08716041 0.95081883] \n",
      " [0.33912555 0.37344829 0.57183529]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print('Data Iris')\n",
    "load, target = load_iris(return_X_y=True)\n",
    "iris_data = pd.DataFrame(load, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "iris_data['label'] = pd.Series(target)\n",
    "\n",
    "net = Network(4, 4)\n",
    "net.fit(load, target, epoch_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.11740136 8.27094941 5.9164251 ] [3.51638315 5.36092207 1.32702712]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.1531494133005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.random.uniform(1, 10, 3)\n",
    "j = np.random.uniform(1, 10, 3)\n",
    "print(o, j)\n",
    "np.dot(o, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(1,1,(3,5))\n",
    "b = np.random.uniform(1,10,(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]] \n",
      "\n",
      "[[4.34001615 8.84582444 5.36002125 8.67189147 5.18367231]\n",
      " [8.42507471 4.31171515 7.97301027 6.15631649 9.27238015]\n",
      " [7.58748903 6.40231917 8.78151948 7.05457473 4.83981053]] \n",
      "\n",
      "[[ 5.34001615  9.84582444  6.36002125  9.67189147  6.18367231]\n",
      " [ 9.42507471  5.31171515  8.97301027  7.15631649 10.27238015]\n",
      " [ 8.58748903  7.40231917  9.78151948  8.05457473  5.83981053]]\n"
     ]
    }
   ],
   "source": [
    "print(a, '\\n')\n",
    "print(b, '\\n')\n",
    "print(np.add(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 5.]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.uniform(1,1,5)\n",
    "print(a)\n",
    "a = np.append(a, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
