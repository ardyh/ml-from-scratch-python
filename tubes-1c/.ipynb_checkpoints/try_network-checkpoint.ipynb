{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "  #constructor\n",
    "  def __init__(self, n_inputs, n_hidden, n_outputs=3, bias=1, learning_rate=0.1):\n",
    "    self.n_inputs = n_inputs # number of input unit\n",
    "    self.n_hidden = n_hidden # number of hidden unit\n",
    "    self.n_outputs = n_outputs # number of output unit\n",
    "    self.bias = bias # bias parameter\n",
    "    self.learning_rate = learning_rate\n",
    "    \n",
    "    # parameters of weight on input to hidden layer \n",
    "    self.weights_ItoH = np.random.uniform(-1, 1, (n_inputs+1, n_hidden)) \n",
    "    self.dweights_ItoH = np.zeros((n_inputs+1, n_hidden))\n",
    "    \n",
    "    # parameters of weight on hidden to output layer \n",
    "    self.weights_HtoO = np.random.uniform(-1, 1, (n_hidden+1, n_outputs))\n",
    "    self.dweights_HtoO = np.zeros((n_hidden+1, n_outputs))\n",
    "    \n",
    "    # output value and error of hidden layer\n",
    "    self.pre_activation_H = np.zeros(n_hidden)\n",
    "    self.post_activation_H = np.zeros(n_hidden)\n",
    "    self.error_H = np.zeros(n_hidden)\n",
    "    \n",
    "    # output value and error of output layer\n",
    "    self.pre_activation_O = np.zeros(n_outputs)\n",
    "    self.post_activation_O = np.zeros(n_outputs)\n",
    "    self.error_O = np.zeros(n_outputs)\n",
    "  \n",
    "  # Net calculation method\n",
    "  ## Calculate net for an input\n",
    "  def calculate_net_ItoH(self, sample, node):\n",
    "    input_plus_bias = np.append(self.data[sample,:], self.bias)\n",
    "    return np.dot(input_plus_bias, self.weights_ItoH[:, node])\n",
    "  ## Calculate net for a hidden unit\n",
    "  def calculate_net_HtoO(self, node):\n",
    "    hidden_plus_bias =  np.append(self.post_activation_H, self.bias)\n",
    "    return np.dot(hidden_plus_bias, self.weights_HtoO[:, node])\n",
    "\n",
    "  # activation function\n",
    "  def activation(self, x):\n",
    "  \treturn 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "  def one_hot_encode(self, target):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    new_target = target.reshape(len(target), 1)\n",
    "    target_encode = encoder.fit_transform(new_target)\n",
    "    return target_encode\n",
    "\n",
    "  #fit the network to the data\n",
    "  def fit(self, data, target, epoch_limit=100, mini_batch_limit=10):\n",
    "    self.data = data\n",
    "    self.target = self.one_hot_encode(target)\n",
    "    self.epoch_limit = epoch_limit\n",
    "\n",
    "    len_data = len(data)\n",
    "\n",
    "    # iterate each epoch\n",
    "    for epoch in range(epoch_limit):\n",
    "\n",
    "      #iterate each instance\n",
    "      mini_batch_count = 0\n",
    "      for instance in range(len_data):\n",
    "            \n",
    "        # From input layer to hidden layer\n",
    "        ## iterate every hidden layer to fill the values\n",
    "        for hidden_unit in range(self.n_hidden):\n",
    "          ### calculate the net input\n",
    "          self.pre_activation_H[hidden_unit] = self.calculate_net_ItoH(instance, hidden_unit)\n",
    "          ### calculate the activated value\n",
    "          self.post_activation_H[hidden_unit] = self.activation(self.pre_activation_H[hidden_unit])\n",
    "\n",
    "        # From hidden layer to output layer\n",
    "        for output_unit in range(self.n_outputs):\n",
    "          ### calculate the net input\n",
    "          self.pre_activation_O[output_unit] = self.calculate_net_HtoO(output_unit)\n",
    "          ### calculate the activated value\n",
    "          self.post_activation_O[output_unit] = self.activation(self.pre_activation_O[output_unit])\n",
    "\n",
    "        # Backpropagation\n",
    "        ## if already at minibatch limit or at the last instance, update the weight \n",
    "        if((mini_batch_count == mini_batch_limit) or (instance == len_data - 1)):\n",
    "          \n",
    "          #update weight - input to hidden\n",
    "          self.weights_ItoH = np.add(self.weights_ItoH, self.dweights_ItoH)\n",
    "          #update weight - hidden to output\n",
    "          self.weights_HtoO = np.add(self.weights_HtoO, self.dweights_HtoO)\n",
    "\n",
    "          #reset delta weight to zero\n",
    "          self.dweights_ItoH = np.zeros((self.n_inputs+1, self.n_hidden))\n",
    "          self.dweights_HtoO = np.zeros((self.n_hidden+1, self.n_outputs))\n",
    "\n",
    "          #reset iterator\n",
    "          mini_batch_count = 0\n",
    "        \n",
    "        ## if below minibatch limit, update delta-weight\n",
    "        else:\n",
    "          ### update delta-weight from output\n",
    "          for hidden_unit in range(self.n_hidden + 1): # (+1 accomodating bias)\n",
    "            for output_unit in range(self.n_outputs):\n",
    "              #### (Minus sign merged). Formula: (target_ok - out_ok) * out_ok * (1 - out_ok) * out_hj\n",
    "              target_o = self.target[instance][output_unit]\n",
    "              out_o = self.post_activation_O[output_unit]\n",
    "              \n",
    "              ##### calculating weight of bias\n",
    "              if (hidden_unit == self.n_hidden): \n",
    "                out_h = self.bias\n",
    "              ##### calculating weight of activated hidden unit\n",
    "              else:\n",
    "                out_h = self.post_activation_H[hidden_unit]\n",
    "\n",
    "              self.error_O[output_unit] = (target_o - out_o) * out_o * (1 - out_o) \n",
    "              self.dweights_HtoO[hidden_unit][output_unit] += self.error_O[output_unit] * out_h * self.learning_rate\n",
    "\n",
    "          ### update delta-weight from hidden layer\n",
    "          for input_unit in range(self.n_inputs + 1): # (+1 accomodating bias)\n",
    "            for hidden_unit in range(self.n_hidden):\n",
    "              #### Formula: sigma_ok(error_o * w_ho) * out_hj * (1 - out_hj) * input_i\n",
    "              sigma_err_output = np.dot(self.error_O, self.weights_HtoO[hidden_unit,:])\n",
    "              out_h = self.post_activation_H[hidden_unit]\n",
    "\n",
    "              ##### calculating weight of bias\n",
    "              if(input_unit == self.n_inputs): \n",
    "                input_i = self.bias\n",
    "              ##### calculating weight of input unit\n",
    "              else:\n",
    "                input_i = self.data[instance, input_unit] \n",
    "              \n",
    "              self.error_H[hidden_unit] = sigma_err_output * out_h * (1 - out_h) \n",
    "              self.dweights_ItoH[input_unit][hidden_unit] += self.error_H[hidden_unit] * input_i * self.learning_rate\n",
    "          \n",
    "          #increment iterator\n",
    "          mini_batch_count += 1\n",
    "        \n",
    "        \n",
    "\n",
    "  def predict(self, data):\n",
    "    self.data = data\n",
    "    result = []\n",
    "    #iterate each instance\n",
    "    for instance in range(len(data)):      \n",
    "      ## iterate every hidden layer to fill the values\n",
    "      for hidden_unit in range(self.n_hidden):\n",
    "        ### calculate the net input\n",
    "        self.pre_activation_H[hidden_unit] = self.calculate_net_ItoH(instance, hidden_unit)\n",
    "        ### calculate the activated value\n",
    "        self.post_activation_H[hidden_unit] = self.activation(self.pre_activation_H[hidden_unit])\n",
    "\n",
    "      max_value = 0\n",
    "      max_index = -1 \n",
    "      # From hidden layer to output layer\n",
    "      for output_unit in range(self.n_outputs):\n",
    "        ### calculate the net input\n",
    "        self.pre_activation_O[output_unit] = self.calculate_net_HtoO(output_unit)\n",
    "        ### calculate the activated value\n",
    "        self.post_activation_O[output_unit] = self.activation(self.pre_activation_O[output_unit])\n",
    "        if(self.post_activation_O[output_unit] >= max_value ):\n",
    "          max_value = self.post_activation_O[output_unit]\n",
    "          max_index = output_unit\n",
    "      \n",
    "      print(self.post_activation_O)\n",
    "      print('instance no:', instance, 'prediction result:', max_index)\n",
    "      result = np.append(result, max_index)\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "  def print_w_ItoH(self):\n",
    "    index=[]\n",
    "    for n in range(n_inputs+2):\n",
    "      index.append('WInput'+str(n))\n",
    "    column=[]\n",
    "    for n in range(n_hidden+1):\n",
    "      column.append('Hidden'+str(n))\n",
    "    return pd.DataFrame(net.weights_ItoH,index,column) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Iris\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print('Data Iris')\n",
    "load, target = load_iris(return_X_y=True)\n",
    "iris_data = pd.DataFrame(load, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "iris_data['label'] = pd.Series(target)\n",
    "\n",
    "shuffled_data = iris_data.copy().sample(frac=1)\n",
    "train_X = shuffled_data.drop('label',axis=1,inplace=False).values\n",
    "train_y = shuffled_data['label'].values\n",
    "\n",
    "net = Network(4, 4)\n",
    "net.fit(load, target, epoch_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  label\n",
       "0             5.1          3.5           1.4          0.2      0\n",
       "1             4.9          3.0           1.4          0.2      0\n",
       "2             4.7          3.2           1.3          0.2      0\n",
       "3             4.6          3.1           1.5          0.2      0\n",
       "4             5.0          3.6           1.4          0.2      0\n",
       "..            ...          ...           ...          ...    ...\n",
       "145           6.7          3.0           5.2          2.3      2\n",
       "146           6.3          2.5           5.0          1.9      2\n",
       "147           6.5          3.0           5.2          2.0      2\n",
       "148           6.2          3.4           5.4          2.3      2\n",
       "149           5.9          3.0           5.1          1.8      2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00268437 0.12375953 0.87443385]\n",
      "instance no: 0 prediction result: 2\n",
      "[0.94359778 0.12393656 0.00176518]\n",
      "instance no: 1 prediction result: 0\n",
      "[0.94640347 0.1207129  0.00167635]\n",
      "instance no: 2 prediction result: 0\n",
      "[0.94691317 0.12009138 0.00166035]\n",
      "instance no: 3 prediction result: 0\n",
      "[0.00236563 0.11278589 0.8869293 ]\n",
      "instance no: 4 prediction result: 2\n",
      "[0.94351244 0.12399889 0.00176781]\n",
      "instance no: 5 prediction result: 0\n",
      "[0.00255498 0.11941927 0.87946011]\n",
      "instance no: 6 prediction result: 2\n",
      "[0.0129396  0.34826069 0.61156529]\n",
      "instance no: 7 prediction result: 2\n",
      "[0.00982899 0.32714147 0.67181209]\n",
      "instance no: 8 prediction result: 2\n",
      "[0.94590547 0.12109732 0.00169231]\n",
      "instance no: 9 prediction result: 0\n",
      "[0.01234062 0.34480323 0.62218261]\n",
      "instance no: 10 prediction result: 2\n",
      "[0.00242726 0.11452891 0.88446523]\n",
      "instance no: 11 prediction result: 2\n",
      "[0.94802404 0.11883779 0.00162517]\n",
      "instance no: 12 prediction result: 0\n",
      "[0.94770782 0.11919257 0.00163516]\n",
      "instance no: 13 prediction result: 0\n",
      "[0.00427378 0.16927675 0.81792803]\n",
      "instance no: 14 prediction result: 2\n",
      "[0.00268927 0.12482572 0.87425022]\n",
      "instance no: 15 prediction result: 2\n",
      "[0.01576085 0.40719872 0.56617292]\n",
      "instance no: 16 prediction result: 2\n",
      "[0.94395264 0.12350645 0.00175412]\n",
      "instance no: 17 prediction result: 0\n",
      "[0.00479031 0.19433687 0.80146926]\n",
      "instance no: 18 prediction result: 2\n",
      "[0.94782636 0.11903436 0.00163148]\n",
      "instance no: 19 prediction result: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 0., 0., 0., 2., 0., 2., 2., 2., 0., 2., 2., 0., 0., 2., 2., 2.,\n",
       "       0., 2., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "shuffled_data = iris_data.sample(n=20)\n",
    "test_X = shuffled_data.drop('label',axis=1,inplace=False).values\n",
    "test_y = shuffled_data['label'].values\n",
    "\n",
    "result = net.predict(test_X)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Network' object has no attribute 'print_w_ItoH'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-6b1eba5ae5b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_w_ItoH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Network' object has no attribute 'print_w_ItoH'"
     ]
    }
   ],
   "source": [
    "net.print_w_ItoH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Output1</th>\n",
       "      <th>Output2</th>\n",
       "      <th>Output3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WHidden0</th>\n",
       "      <td>-1.485031</td>\n",
       "      <td>-1.833414</td>\n",
       "      <td>1.386095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHidden1</th>\n",
       "      <td>0.291866</td>\n",
       "      <td>-0.589625</td>\n",
       "      <td>0.081247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHidden2</th>\n",
       "      <td>5.603008</td>\n",
       "      <td>-3.258912</td>\n",
       "      <td>-5.341368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whidden3</th>\n",
       "      <td>-1.869708</td>\n",
       "      <td>-1.485163</td>\n",
       "      <td>1.762046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whidden4</th>\n",
       "      <td>-2.693408</td>\n",
       "      <td>1.252115</td>\n",
       "      <td>-1.084940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Output1   Output2   Output3\n",
       "WHidden0 -1.485031 -1.833414  1.386095\n",
       "WHidden1  0.291866 -0.589625  0.081247\n",
       "WHidden2  5.603008 -3.258912 -5.341368\n",
       "Whidden3 -1.869708 -1.485163  1.762046\n",
       "Whidden4 -2.693408  1.252115 -1.084940"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['WHidden0','WHidden1','WHidden2','Whidden3','Whidden4']\n",
    "column=['Output1','Output2','Output3']\n",
    "df_weights_HtoO=pd.DataFrame(net.weights_HtoO,index,column)\n",
    "df_weights_HtoO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WInput0', 'WInput1', 'WInput2', 'WInput3']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=[]\n",
    "for n in range(4):\n",
    "    index.append('WInput'+str(n))\n",
    "index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
