{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "  #constructor\n",
    "  def __init__(self, n_inputs, n_hidden, n_outputs=3, bias=1):\n",
    "    self.n_inputs = n_inputs # number of input unit\n",
    "    self.n_hidden = n_hidden # number of hidden unit\n",
    "    self.n_outputs = n_outputs # number of output unit\n",
    "    self.bias = bias # bias parameter\n",
    "    \n",
    "    # parameters of weight on input to hidden layer \n",
    "    self.weights_ItoH = np.random.uniform(-1, 1, (n_inputs+1, n_hidden)) \n",
    "    self.dweights_ItoH = np.zeros((n_inputs+1, n_hidden))\n",
    "    \n",
    "    # parameters of weight on hidden to output layer \n",
    "    self.weights_HtoO = np.random.uniform(-1, 1, (n_hidden+1, n_outputs))\n",
    "    self.dweights_HtoO = np.zeros((n_hidden+1, n_outputs))\n",
    "    \n",
    "    # output value and error of hidden layer\n",
    "    self.pre_activation_H = np.zeros(n_hidden)\n",
    "    self.post_activation_H = np.zeros(n_hidden)\n",
    "    self.error_H = np.zeros(n_hidden)\n",
    "    \n",
    "    # output value and error of output layer\n",
    "    self.pre_activation_O = np.zeros(n_outputs)\n",
    "    self.post_activation_O = np.zeros(n_outputs)\n",
    "    self.error_O = np.zeros(n_outputs)\n",
    "  \n",
    "  # Net calculation method\n",
    "  ## Calculate net for an input\n",
    "  def calculate_net_ItoH(self, sample, node):\n",
    "    input_plus_bias = np.append(self.data[sample,:], self.bias)\n",
    "    return np.dot(input_plus_bias, self.weights_ItoH[:, node])\n",
    "  ## Calculate net for a hidden unit\n",
    "  def calculate_net_HtoO(self, node):\n",
    "    hidden_plus_bias =  np.append(self.post_activation_H, self.bias)\n",
    "    return np.dot(hidden_plus_bias, self.weights_HtoO[:, node])\n",
    "\n",
    "  # activation function\n",
    "  def activation(self, x):\n",
    "  \treturn 1.0/(1 + np.exp(-x))\n",
    "  \n",
    "  # Derivation of activation function\n",
    "  def activation_deriv(self, x):\n",
    "    return activation(x) * (1 - activation(x))\n",
    "\n",
    "  def one_hot_encode(self, target):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    new_target = target.reshape(len(target), 1)\n",
    "    target_encode = encoder.fit_transform(new_target)\n",
    "    return target_encode\n",
    "\n",
    "  #fit the network to the data\n",
    "  def fit(self, data, target, epoch_limit=100, mini_batch_limit=10):\n",
    "    self.data = data\n",
    "    self.target = self.one_hot_encode(target)\n",
    "    self.epoch_limit = epoch_limit\n",
    "\n",
    "    len_data = len(data)\n",
    "\n",
    "    # iterate each epoch\n",
    "    for epoch in range(epoch_limit):\n",
    "      \n",
    "      #iterate each instance\n",
    "      mini_batch_count = 0\n",
    "      for instance in range(len_data):\n",
    "            \n",
    "        # From input layer to hidden layer\n",
    "        ## iterate every hidden layer to fill the values\n",
    "        for hidden_unit in range(self.n_hidden):\n",
    "          ### calculate the net input\n",
    "          self.pre_activation_H[hidden_unit] = self.calculate_net_ItoH(instance, hidden_unit)\n",
    "          ### calculate the activated value\n",
    "          self.post_activation_H[hidden_unit] = self.activation(self.pre_activation_H[hidden_unit])\n",
    "\n",
    "        # From hidden layer to output layer\n",
    "        for output_unit in range(self.n_outputs):\n",
    "          ### calculate the net input\n",
    "          self.pre_activation_O[output_unit] = self.calculate_net_HtoO(output_unit)\n",
    "          ### calculate the activated value\n",
    "          self.post_activation_O[output_unit] = self.activation(self.pre_activation_O[output_unit])\n",
    "      \n",
    "        #for debug\n",
    "#         print('INSTANCE:', instance )\n",
    "#         print('WEIGHTS\\n', self.weights_ItoH, '\\n', self.weights_HtoO)\n",
    "#         print('OUTPUTS\\n', self.post_activation_H, '\\n', self.post_activation_O)\n",
    "\n",
    "        # Backpropagation\n",
    "        ## if already at minibatch limit or at the last instance, update the weight \n",
    "        if((mini_batch_count == mini_batch_limit) or (instance == len_data - 1)):\n",
    "          #update weight - hidden to output\n",
    "          self.weights_HtoO = np.add(self.weights_HtoO, self.dweights_HtoO)\n",
    "          \n",
    "          #update weight - input to hidden\n",
    "          self.weights_ItoH = np.add(self.weights_ItoH, self.dweights_ItoH)\n",
    "\n",
    "          mini_batch_count = 0\n",
    "        \n",
    "        ## if below minibatch limit, update delta-weight\n",
    "        else:\n",
    "          ### update delta-weight from output\n",
    "          for hidden_unit in range(self.n_hidden + 1): # (+1 accomodating bias)\n",
    "            for output_unit in range(self.n_outputs):\n",
    "              #### (Minus sign merged). Formula: (target_ok - out_ok) * out_ok * (1 - out_ok) * out_hj\n",
    "              target_o = self.target[instance][output_unit]\n",
    "              out_o = self.post_activation_O[output_unit]\n",
    "              \n",
    "              ##### calculating weight of bias\n",
    "              if (hidden_unit == self.n_hidden): \n",
    "                out_h = self.bias\n",
    "              ##### calculating weight of activated hidden unit\n",
    "              else:\n",
    "                out_h = self.post_activation_H[hidden_unit]\n",
    "\n",
    "              self.error_O[output_unit] = (target_o - out_o) * out_o * (1 - out_o)\n",
    "              self.dweights_HtoO[hidden_unit][output_unit] += self.error_O[output_unit] * out_h\n",
    "\n",
    "          ### update delta-weight from hidden layer\n",
    "          for input_unit in range(self.n_inputs + 1): # (+1 accomodating bias)\n",
    "            for hidden_unit in range(self.n_hidden):\n",
    "              #### Formula: sigma_ok(error_o * w_ho) * out_hj * (1 - out_hj) * input_i\n",
    "              sigma_err_output = np.dot(self.error_O, self.weights_HtoO[hidden_unit,:])\n",
    "              out_h = self.post_activation_H[hidden_unit]\n",
    "\n",
    "              ##### calculating weight of bias\n",
    "              if(input_unit == self.n_inputs): \n",
    "                input_i = self.bias\n",
    "              ##### calculating weight of input unit\n",
    "              else:\n",
    "                input_i = self.data[instance, input_unit] \n",
    "              \n",
    "              self.error_H[hidden_unit] = sigma_err_output * out_h * (1 - out_h)\n",
    "              self.dweights_ItoH[input_unit][hidden_unit] += self.error_H[hidden_unit] * input_i\n",
    "\n",
    "          mini_batch_count += 1\n",
    "        \n",
    "\n",
    "  def predict(self, data):\n",
    "    self.data = data\n",
    "    result = np.zeros(len(data))\n",
    "    #iterate each instance\n",
    "    for instance in range(len(data)):      \n",
    "      ## iterate every hidden layer to fill the values\n",
    "      for hidden_unit in range(self.n_hidden):\n",
    "        ### calculate the net input\n",
    "        self.pre_activation_H[hidden_unit] = self.calculate_net_ItoH(instance, hidden_unit)\n",
    "        ### calculate the activated value\n",
    "        self.post_activation_H[hidden_unit] = self.activation(self.pre_activation_H[hidden_unit])\n",
    "\n",
    "      max_value = 0\n",
    "      max_index = -1 \n",
    "      # From hidden layer to output layer\n",
    "      for output_unit in range(self.n_outputs):\n",
    "        ### calculate the net input\n",
    "        self.pre_activation_O[output_unit] = self.calculate_net_HtoO(output_unit)\n",
    "        ### calculate the activated value\n",
    "        self.post_activation_O[output_unit] = self.activation(self.pre_activation_O[output_unit])\n",
    "        print(self.post_activation_O, output_unit, self.post_activation_O[output_unit], max_value)\n",
    "        if(self.post_activation_O[output_unit] >= max_value ):\n",
    "          max_value = self.post_activation_O\n",
    "          max_index = output_unit\n",
    "      print('instance no:', instance, 'prediction result:', max_index)\n",
    "      result.append(max_index)\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Iris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print('Data Iris')\n",
    "load, target = load_iris(return_X_y=True)\n",
    "iris_data = pd.DataFrame(load, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "iris_data['label'] = pd.Series(target)\n",
    "\n",
    "net = Network(4, 4)\n",
    "net.fit(load, target, epoch_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 4.22955723e-16 1.05964703e-13] 0\n",
      "[1.00000000e+00 3.53133625e-17 1.05964703e-13] 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d4777aa028f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pred Result\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original Data\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-76aaec51e498>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_activation_O\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_unit\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_activation_O\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_unit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_activation_O\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_unit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_activation_O\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_unit\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m           \u001b[0mmax_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_activation_O\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m           \u001b[0mmax_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_unit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "result = net.predict(load[:20])\n",
    "print(\"Pred Result\\n\", result, sep='')\n",
    "print(\"Original Data\\n\", label[:20], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.11740136 8.27094941 5.9164251 ] [3.51638315 5.36092207 1.32702712]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.1531494133005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.random.uniform(1, 10, 3)\n",
    "j = np.random.uniform(1, 10, 3)\n",
    "print(o, j)\n",
    "np.dot(o, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(1,1,(3,5))\n",
    "b = np.random.uniform(1,10,(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]] \n",
      "\n",
      "[[4.34001615 8.84582444 5.36002125 8.67189147 5.18367231]\n",
      " [8.42507471 4.31171515 7.97301027 6.15631649 9.27238015]\n",
      " [7.58748903 6.40231917 8.78151948 7.05457473 4.83981053]] \n",
      "\n",
      "[[ 5.34001615  9.84582444  6.36002125  9.67189147  6.18367231]\n",
      " [ 9.42507471  5.31171515  8.97301027  7.15631649 10.27238015]\n",
      " [ 8.58748903  7.40231917  9.78151948  8.05457473  5.83981053]]\n"
     ]
    }
   ],
   "source": [
    "print(a, '\\n')\n",
    "print(b, '\\n')\n",
    "print(np.add(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 5.]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.uniform(1,1,5)\n",
    "print(a)\n",
    "a = np.append(a, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
