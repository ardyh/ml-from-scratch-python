{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation - ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements:\n",
    "\n",
    "#### Diturunkan Sendiri:\n",
    "- Program bisa membuat sebuah objek pohon yang bisa menyimpan attributes dari tree (v)\n",
    "- Objek pohon dapat membuat decision tree dari data yang diberikan, dan menyimpan atribut-atribut dari pohon tersebut (v)\n",
    "- Objek pohon dapat menyimpan node-node yang merupakan splitting points untuk membuat keputusan (v)\n",
    "- Objek pohon dapat mengakses seluruh node yang ada pada pohon\n",
    "- Objek pohon dapat memilih splitting point untuk tiap keadaan; apakah menggunakan metrik information gain atau gain ratio (v)\n",
    "- Objek pohon dapat mempertimbangkan atribut yang value-nya continuous dan diskrit (v)\n",
    "- Objek pohon dapat mempertimbangkan atribut yang mempunyai missing value (v)\n",
    "- Objek pohon dapat melakukan post-pruning dengan menggunakan 20% data untuk validasi. Detil pruning kurang lebih: https://www.quora.com/How-can-I-find-a-real-step-by-step-example-of-a-decision-tree-pruning-to-overcome-overfitting\n",
    "- Objek pohon dapat menampilkan pohon yang dibuat\n",
    "- Objek node dapat melakukan splitting pada dataset (menentukan keputusan harus ke node mana setelah suatu kondisi)\n",
    "    - Objek node tahu harus melakukan splitting pada atribut apa\n",
    "    - Objek node menyimpan splitting points pada atribut yang bersangkutan\n",
    "\n",
    "#### Dari Spek:\n",
    "- Overfitting training data dengan post pruning. Gunakanlah 20% training data untuk data validasi.\n",
    "- Continuous-valued attribute: information gain dari kandidate. (v)\n",
    "- Alternative measures for selecting attributes: gain ratio. (v)\n",
    "- Handling missing attribute value: most common target value. (v)\n",
    "- full-training the data \n",
    "- menampilkan modelnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n",
      "0.6428571428571429\n",
      "0.35714285714285715\n",
      "Empty DataFrame\n",
      "Columns: [day, outlook, temp, humidity, wind, play]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"play_tennis.csv\")\n",
    "data.head()\n",
    "proportion = data['play'].value_counts()/len(data)\n",
    "print(proportion[0])\n",
    "entropy = 0\n",
    "for p in proportion.tolist():\n",
    "    print(p)\n",
    "    entropy -= p*math.log(p,2)\n",
    "    \n",
    "print(data[data['outlook'] == 'sunny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read iris data\n",
    "load, target = load_iris(return_X_y=True)\n",
    "iris_data = pd.DataFrame(load, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "iris_data['label'] = pd.Series(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisi kelas Node\n",
    "#Node merupakan split point pada tree. \n",
    "#Kelas ini menyimpan data yang ada pada suatu split point, atribut apa yang digunakan untuk splitting, dan tipe atribut tsb. Atau jika node merupakan daun maka disimpan value-nya\n",
    "#Kelas ini dapat menentukan splitting point kebawah dari suatu node, baik atribut splittingnya kontinu maupun diskrit\n",
    "#Atribut-atribut Node: \n",
    "# - data: subset data\n",
    "# - split_attr: nama atribut yang akan di split\n",
    "# - split_values: value cabang dari node (merupakan satu integer jika continuous, dan multiple values jika categorical)\n",
    "# - target_attr: atribut label/atribut target prediksi\n",
    "# - attr_cont_split: splitting point dari atribut tsb (jika atribut tsb kontinu)\n",
    "# - is_leaf: apakah node merupakan daun atau tidak\n",
    "# - leaf_value: nilai hasil prediksi jika node merupakan daun\n",
    "# - childs: anak dari node yang berupa node\n",
    "class Node:\n",
    "    #konstruktor\n",
    "    def __init__(self, data, split_attr, target_attr, is_continuous=False, split_value_continuous=None, is_leaf=False, leaf_value=None, parent_value=None):\n",
    "        self.data = data\n",
    "        self.split_attr = split_attr\n",
    "        self.target_attr = target_attr\n",
    "        self.childs = []\n",
    "        self.is_leaf = is_leaf\n",
    "        self.split_values = [split_value_continuous]\n",
    "        self.leaf_value = leaf_value\n",
    "        self.parent_value = parent_value\n",
    "\n",
    "    #check apakah split attribute == numerik\n",
    "    def is_attr_categorical(self):\n",
    "        return self.data[self.split_attr].dtype == 'O'\n",
    "    \n",
    "    #get splits node jika node bukan daun\n",
    "    def get_splits(self):\n",
    "        if( not self.check_if_leaf()):\n",
    "            #jika atribut split categorical\n",
    "            if(self.is_attr_categorical()):\n",
    "                #tentukan split values\n",
    "                self.split_values = self.data[self.split_attr].unique()\n",
    "            #jika atribut numerik / continuous, split value sudah didefinisikan sejak konstruksi objek\n",
    "            return self.split_values\n",
    "                        \n",
    "    #add a child to a node\n",
    "    def add_child(self, node):\n",
    "        self.childs.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisi kelas Tree\n",
    "#Kelas ini mengkonstruksi decision tree dengan menghubungkan sekumpulan node, juga memilih untuk tiap node \n",
    "#atribut apa yang akan digunakan untuk splitting. Kelas ini dapat mempertimbangkan atribut yang mengandung nilai null.\n",
    "#Metrik yang  digunakan bisa dipilih antara information gain atau gain ratio.\n",
    "#Kelas ini dapat melakukan pruning pada tree yang dibuat, dan juga dapat mencetak model tree yang telah dibuat\n",
    "#NOTE: Asumsi missing value, bernilai \"None\" atau \"none\"\n",
    "#Atribut-atribut Tree:\n",
    "# - data: merupakan data yang digunakan untuk training\n",
    "# - target_attr: atribut yang menjadi target prediksi (label)\n",
    "# - root: node yang merupakan root\n",
    "# - use_info_gain: True/False. Jika true maka metrik pemilihan atribut menggunakan information gain. Jika False, metrik menggunakan gain ratio\n",
    "class Tree:\n",
    "    #konstruktor\n",
    "    def __init__(self, data, target_attr, use_info_gain=True,root_value=None):\n",
    "        self.data = data\n",
    "        self.target_attr = target_attr\n",
    "        self.root = None\n",
    "        self.root_value = root_value\n",
    "        self.use_info_gain = use_info_gain\n",
    "        self.ruleset = []\n",
    "        self.accuracy_ori = None\n",
    "    \n",
    "    #cari entropi total pada data\n",
    "    def total_entropy(self, data):\n",
    "        proportion = data[self.target_attr].value_counts()/len(data)\n",
    "        entropy = 0\n",
    "        for p in proportion.tolist():\n",
    "            entropy -= p*math.log(p,2)\n",
    "        return entropy\n",
    "    \n",
    "    #hitung information gain dari suatu kolom\n",
    "    def info_gain(self, kolom):\n",
    "        data = self.data\n",
    "        data_entropy = self.total_entropy(data)\n",
    "        proportion_kolom = data[kolom].value_counts()/len(data)\n",
    "        sum_entropy_kolom = 0\n",
    "        for value_kolom, value_proportion in zip(proportion_kolom.index.tolist(), proportion_kolom.tolist()):\n",
    "            #print(\"here checking\")\n",
    "            #print(data[data[kolom] == value_kolom])\n",
    "            entropy_value_kolom = self.total_entropy(data[data[kolom] == value_kolom])\n",
    "            sum_entropy_kolom -= value_proportion*entropy_value_kolom\n",
    "            \n",
    "        return data_entropy + sum_entropy_kolom\n",
    "    \n",
    "    #hitung information split pada data di suatu atribut\n",
    "    def split_info(self, attr):\n",
    "        proportion = self.data[attr].value_counts()/len(data)\n",
    "        split_info = 0\n",
    "        for p in proportion.tolist():\n",
    "            split_info -= p*math.log(p,2)\n",
    "        return split_info\n",
    "    \n",
    "    #hitung gain ratio untuk suatu atribut\n",
    "    def gain_ratio(self, attr):\n",
    "        return info_gain(attr)/split_info(attr)\n",
    "    \n",
    "    #cari split-split yang memungkinkan pada atribut continuous\n",
    "    def find_possible_splits_continuous(self, sorted_data, split_attr):\n",
    "        sorted_target = sorted_data[self.target_attr].values.tolist()\n",
    "        sorted_attr = sorted_data[split_attr].values.tolist()\n",
    "        prev_target_value = sorted_target[0]\n",
    "        possible_splits = []\n",
    "        #iterasi target value, cari titik-titik dimana \n",
    "        try:\n",
    "            for i in range(1, len(sorted_target)):\n",
    "                el = sorted_target[i]\n",
    "                if (prev_target_value != el):\n",
    "                    possible_splits.append(0.5*(sorted_attr[i] + sorted_attr[i-1]))\n",
    "                prev_target_value = el\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            return possible_splits\n",
    "    \n",
    "    #cari gain dari tiap split dan cari split optimum\n",
    "    def find_optimum_split_continuous(self, pos_splits, sorted_data, split_attr):\n",
    "        optimum_split = 0\n",
    "        max_info_gain = -1\n",
    "        #iterate split\n",
    "        for i, el in enumerate(pos_splits):\n",
    "            #hitung information gain\n",
    "            current_gain = self.calculate_info_gain_continuous(el, sorted_data, split_attr)\n",
    "            #jika information gain lebih dari sebelumnya, ganti optimum split\n",
    "            if(current_gain > max_info_gain):\n",
    "                max_info_gain = current_gain\n",
    "                optimum_split = el\n",
    "        return optimum_split\n",
    "    \n",
    "    #cari information gain pada suatu split continuous\n",
    "    def calculate_info_gain_continuous(self, split_value, sorted_data, split_attr):\n",
    "        data_entropy = self.total_entropy(sorted_data)\n",
    "        #pisah data mjd \"<=\" dan \">\" split_value\n",
    "        data_less_than_equal = sorted_data[sorted_data[split_attr] <= split_value]\n",
    "        data_more_than = sorted_data[sorted_data[split_attr] > split_value]\n",
    "        #hitung entropi kolom\n",
    "        entropy_less_than_equal = (float(len(data_less_than_equal))/len(sorted_data)) * self.total_entropy(data_less_than_equal)\n",
    "        entropy_more_than = (float(len(data_more_than))/len(sorted_data)) * self.total_entropy(data_more_than)\n",
    "        return data_entropy - entropy_less_than_equal - entropy_more_than\n",
    "    \n",
    "    #check apakah attribute == numerik\n",
    "    def is_attr_categorical(self, attr):\n",
    "        return self.data[attr].dtype == 'O'\n",
    "    \n",
    "    #handling missing value\n",
    "    def handle_missing_value(self, split_attr):\n",
    "        if(self.is_attr_categorical(split_attr)):\n",
    "            mode = self.data[split_attr].mode().values[0]\n",
    "            self.data[split_attr] = self.data[split_attr].replace({None:mode})        \n",
    "    \n",
    "    #buat tree\n",
    "    def make_tree(self):\n",
    "        #cari info_gain dari masing-masing kolom \n",
    "        data_X = self.data.drop(self.target_attr, axis=1)\n",
    "        \n",
    "        #basis-1: jika data terbagi dg sempurna\n",
    "        if(self.data[self.target_attr].nunique() == 1):\n",
    "            self.root = Node(\"none\", \"none\", self.target_attr, is_leaf=True, leaf_value=self.data[self.target_attr].unique()[0], parent_value=self.root_value)\n",
    "            return self.root\n",
    "        \n",
    "        #basis-2: jika tidak ada atribut\n",
    "        if(len(data_X.columns) == 0):\n",
    "            self.root = Node(\"none\", \"none\", self.target_attr, is_leaf=True, leaf_value=self.data[self.target_attr].mode().values[0], parent_value=self.root_value)\n",
    "            return self.root\n",
    "        \n",
    "        #rekurens, jika data tidak bisa mjd leaf\n",
    "        else:\n",
    "            max_metric = -1\n",
    "            split_attr = \"\"\n",
    "            is_split_attr_categorical = True\n",
    "            for attr in data_X.columns:\n",
    "                #Jika kolom kategorikal\n",
    "                if(self.is_attr_categorical(attr)):\n",
    "                    if(self.use_info_gain):\n",
    "                        current_metric = self.info_gain(attr)\n",
    "                    else:\n",
    "                        current_metric = self.gain_ratio(attr)\n",
    "                #jika kolom numerik\n",
    "                else:\n",
    "                    #sort data\n",
    "                    sorted_data = self.data.sort_values(by=attr)\n",
    "                    #cari split-split yang memungkinkan \n",
    "                    pos_splits = self.find_possible_splits_continuous(sorted_data, attr)\n",
    "                    #hitung gain dari tiap continuous split dan cari nilai optimum\n",
    "                    split_value_continuous = self.find_optimum_split_continuous(pos_splits, sorted_data, attr)\n",
    "                    #hitung gain ketika sudah diketahui nilai optimum\n",
    "                    current_metric = self.calculate_info_gain_continuous(split_value_continuous, sorted_data, attr)\n",
    "\n",
    "                #jika ditemukan maximum info gain di kolom tertentu\n",
    "                if(current_metric > max_metric):\n",
    "                    max_metric = current_metric\n",
    "                    split_attr = attr\n",
    "                    is_split_attr_categorical = self.is_attr_categorical(attr)\n",
    "                    if (not is_split_attr_categorical):\n",
    "                        split_value_attr = split_value_continuous\n",
    "            \n",
    "            #setelah atribut dipilih, cek apakah ada missing value\n",
    "            #impute missing value dengan modus pada atribut tsb. (asumsi: atribut yg di handle hanyalah kategorikal)\n",
    "            self.handle_missing_value(split_attr)\n",
    "            \n",
    "            #buat node\n",
    "            #jika atribut terpilih == kategorikal\n",
    "            if(is_split_attr_categorical):\n",
    "                self.root = Node(self.data, split_attr, self.target_attr, parent_value=self.root_value)\n",
    "                split_values = self.data[split_attr].unique()\n",
    "                #iterate all split values\n",
    "                for split_value in split_values:\n",
    "                    filtered_data = self.data[self.data[split_attr] == split_value].drop(split_attr, axis=1)\n",
    "                    self.root.add_child(Tree(filtered_data, self.target_attr, root_value=split_value).make_tree())\n",
    "\n",
    "            #jika atribut terpilih == numerik & kontinu\n",
    "            else:\n",
    "                self.root = Node(self.data, split_attr, self.target_attr, is_continuous=True, split_value_continuous=split_value_attr, parent_value=self.root_value)\n",
    "                #filter <=\n",
    "                filtered_data = self.data[self.data[split_attr] <= split_value_attr].drop(split_attr, axis=1)\n",
    "                self.root.add_child(Tree(filtered_data, self.target_attr, root_value=\"<=\"+str(split_value_attr)).make_tree())\n",
    "\n",
    "                #filter >\n",
    "                filtered_data = self.data[self.data[split_attr] > split_value_attr].drop(split_attr, axis=1)\n",
    "                self.root.add_child(Tree(filtered_data, self.target_attr, root_value=\">\"+str(split_value_attr)).make_tree())\n",
    "\n",
    "            return self.root\n",
    "\n",
    "    def print_tree(self, node, depth, space):\n",
    "        if (depth == 0):\n",
    "            print('-------tree-------')\n",
    "            dash = ''\n",
    "        else:\n",
    "            dash = '|' + '-'*space + '(' + node.parent_value + ')' + '-'*space + '>'\n",
    "            \n",
    "        if(node.is_leaf):\n",
    "            output = ('|' + ('      '*space))*(depth-1) + dash + '{class : ' + str(node.leaf_value) + '}'\n",
    "        else:\n",
    "            output = ('|' + ('      '*space))*(depth-1) + dash + node.split_attr \n",
    "        \n",
    "        if (node.parent_value):\n",
    "            output = output \n",
    "        \n",
    "        print(output)\n",
    "        \n",
    "        depth += 1\n",
    "        for child in node.childs:\n",
    "            self.print_tree(child, depth, space)\n",
    "            \n",
    "    #bagian rekursif untuk prediksi\n",
    "    def get_prediction_result(self, prediction_instance, node):\n",
    "        #basis - jika node merupakan leaf, kembalikan value\n",
    "        if(node.is_leaf):\n",
    "            return node.leaf_value\n",
    "        \n",
    "        #rekurens - jika node bukan leaf, cari anaknya yang tepat, telusuri anak\n",
    "        else:\n",
    "            #jika node categorical\n",
    "            if(node.is_attr_categorical()):\n",
    "                for child in node.childs:\n",
    "                    if (child.parent_value == prediction_instance[node.split_attr]):\n",
    "                        return self.get_prediction_result(prediction_instance, child)\n",
    "                        break\n",
    "            #jika node numerik/kontinu\n",
    "            else:\n",
    "                if(prediction_instance[node.split_attr] <= node.split_values[0]):\n",
    "                    return self.get_prediction_result(prediction_instance, node.childs[0])\n",
    "                elif(prediction_instance[node.split_attr] > node.split_values[0]):\n",
    "                    return self.get_prediction_result(prediction_instance, node.childs[1])\n",
    "                \n",
    "    #prediksi suatu dataset test\n",
    "    def predict(self, test_data):\n",
    "        print('-------predict-------')\n",
    "        pred_result = []\n",
    "        #iterasi seluruh instance pada test_data\n",
    "        for i in range(len(test_data)):\n",
    "            #instance untuk di prediksi\n",
    "            prediction_instance = test_data.iloc[i]\n",
    "            #get prediction untuk instance yang dicek, lalu append ke hasil\n",
    "            pred_result.append(self.get_prediction_result(prediction_instance, self.root))\n",
    "        return pred_result\n",
    "    \n",
    "    #transformasi tree menjadi kumpulan rule\n",
    "    def recursively_write_rule(self, node, rule):\n",
    "        #basis - mencapai leaf. Append rule ke ruleset\n",
    "        if(node.is_leaf):\n",
    "            new_rule = rule + [[self.target_attr, node.leaf_value]]\n",
    "            self.ruleset.append(new_rule)\n",
    "        \n",
    "        #rekurens - mencatat current precondition dan telusuri anak-anaknya\n",
    "        else:\n",
    "            for child in node.childs:\n",
    "                new_rule = rule + [[node.split_attr, child.parent_value]]\n",
    "                self.recursively_write_rule(child, new_rule)\n",
    "    \n",
    "    #parsing rule menjadi query\n",
    "    def parse_rule(self, rule):\n",
    "        str_rule = ''\n",
    "        for statement in rule[:-1]:\n",
    "            #categorical variable\n",
    "            if (statement[1][0] != \"<\") and (statement[1][0] != \">\"):\n",
    "                str_rule += statement[0] + ' == \"' + statement[1] + '\" and '\n",
    "            else:\n",
    "                str_rule += statement[0] + statement[1] + ' and '\n",
    "        return str_rule[:-4]\n",
    "    \n",
    "    #kalkulasi akurasi suatu rule\n",
    "    def calculate_rule_accuracy(self, rule):\n",
    "        query = self.parse_rule(rule)\n",
    "        filtered_data = self.data_test.query(query)\n",
    "        target_value = rule[-1][1]\n",
    "        num_correct_answers = len(filtered_data[filtered_data[self.target_attr] == target_value])\n",
    "        if(len(filtered_data) == 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return float(num_correct_answers)/float(len(filtered_data))\n",
    "    \n",
    "    #pruning untuk suatu rule\n",
    "    def prune_rule(self, rule, prev_accuracy):\n",
    "        if(len(rule) > 2):\n",
    "            optimal_rule = []\n",
    "            max_accuracy = -1\n",
    "            for statement in rule[:-1]:\n",
    "                temp_rule = rule.copy()\n",
    "                temp_rule.remove(statement)\n",
    "                accuracy = self.calculate_rule_accuracy(temp_rule)\n",
    "                if accuracy > max_accuracy:\n",
    "                    max_accuracy = accuracy\n",
    "                    optimal_rule = temp_rule\n",
    "\n",
    "            #basis - akurasi tidak improve\n",
    "            if((max_accuracy <= prev_accuracy) or (len(rule) == 0)):\n",
    "                return (optimal_rule, rule[-1][-1], max_accuracy)\n",
    "            #rekurens - akurasi masih bisa dinaikkan dengan pruning\n",
    "            else:\n",
    "                return self.prune_rule(optimal_rule, max_accuracy)\n",
    "        else:\n",
    "            return (rule, rule[-1][-1], self.calculate_rule_accuracy(rule))\n",
    "    \n",
    "    #post-pruning\n",
    "    def rule_post_pruning(self, data_test):\n",
    "        print('-------rules-------')\n",
    "        #definisikan rules yang ada\n",
    "        #lakukan DFS pada tree sampai leaf. Catat semua rule yang ada\n",
    "        self.recursively_write_rule(self.root, [])\n",
    "        \n",
    "        #set data test\n",
    "        self.data_test = data_test\n",
    "        \n",
    "        #prune rule\n",
    "        sorted_rule = {}\n",
    "        for i, rule in enumerate(self.ruleset):\n",
    "            pruned_rule, label, accuracy = (self.prune_rule(rule, -1))\n",
    "            sorted_rule[self.parse_rule(pruned_rule)+'; label: '+str(label)] = accuracy\n",
    "\n",
    "        sorted_rule = sorted(sorted_rule.items(), key=lambda kv: kv[1])\n",
    "        return sorted_rule\n",
    "    \n",
    "    #rekurens accuracy_tree\n",
    "    #return 0 jika salah\n",
    "    #return 1 jika benar\n",
    "    def check_result(self, check_instance, node):\n",
    "        #basis - jika node merupakan leaf, kembalikan value\n",
    "        if(node.is_leaf):\n",
    "                return node.leaf_value == check_instance[node.target_attr]\n",
    "        #rekurens - jika node bukan leaf, cari anak\n",
    "        else:\n",
    "            #jika node categorical\n",
    "            if(node.is_attr_categorical()):\n",
    "                for child in node.childs:\n",
    "                    if (child.parent_value == check_instance[node.split_attr]):\n",
    "                        return self.check_result(check_instance, child)\n",
    "                        break\n",
    "                        \n",
    "            #jika node numerik/kontinu\n",
    "            else:\n",
    "                if(check_instance[node.split_attr] <= node.split_values[0]):\n",
    "                    return self.check_result(check_instance, node.childs[0])\n",
    "                elif(check_instance[node.split_attr] > node.split_values[0]):\n",
    "                    return self.check_result(check_instance, node.childs[1])\n",
    "\n",
    "    def accuracy_tree(self, test_data):\n",
    "        success = 0;\n",
    "        #iterasi seluruh instance pada test_data\n",
    "        for i in range(len(test_data)):\n",
    "            #instance untuk di prediksi\n",
    "            success += self.check_result(test_data.iloc[i], self.root)\n",
    "        return success/len(test_data)*100\n",
    "    \n",
    "    def pruning_rek(self, parent, node_child, test_data):\n",
    "        if(parent==self.root):\n",
    "            pass\n",
    "        #basis jika node adalah leaf bandingkan akurasi pruned tree dan original tree\n",
    "        elif(node_child.is_leaf):\n",
    "            parent.is_leaf=True\n",
    "            parent.leaf_value = parent.data[node_child.target_attr].mode().values[0]\n",
    "            if(self.accuracy_tree(test_data)<self.accuracy_ori):\n",
    "                parent.is_leaf=False\n",
    "                parent.leaf_value = None\n",
    "            else:\n",
    "                parent.childs.clear()\n",
    "                self.accuracy_ori = self.accuracy_tree(test_data)\n",
    "        else :\n",
    "            return self.pruning_rek(node_child,node_child.childs[0],test_data)    \n",
    "            \n",
    "    def post_pruning(self, data_val):\n",
    "        self.accuracy_ori=self.accuracy_tree(data_val)\n",
    "        for child in self.root.childs:\n",
    "            if(not(child.is_leaf)):\n",
    "                self.pruning_rek(child, child.childs[0], data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_iris_data = iris_data.sample(frac=1).reset_index().drop('index', axis=1)\n",
    "iris_train_data = randomized_iris_data.iloc[0:120]\n",
    "iris_test_data = randomized_iris_data.iloc[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|--(<=2.45)-->{class : 0}\n",
      "|--(>2.45)-->petal_width\n",
      "|            |--(<=1.75)-->sepal_length\n",
      "|            |            |--(<=7.1)-->sepal_width\n",
      "|            |            |            |--(<=2.2)-->{class : 1}\n",
      "|            |            |            |--(>2.2)-->{class : 1}\n",
      "|            |            |--(>7.1)-->{class : 2}\n",
      "|            |--(>1.75)-->sepal_length\n",
      "|            |            |--(<=5.9)-->sepal_width\n",
      "|            |            |            |--(<=3.1)-->{class : 2}\n",
      "|            |            |            |--(>3.1)-->{class : 1}\n",
      "|            |            |--(>5.9)-->{class : 2}\n",
      "-------rules-------\n",
      "sepal_length<=5.9 and sepal_width>3.1 ; label: 1\n",
      "petal_length>2.45 and petal_width<=1.75 ; label: 1\n",
      "petal_length<=2.45 ; label: 0\n",
      "sepal_length<=7.1 and sepal_width<=2.2 ; label: 1\n",
      "sepal_length>7.1 ; label: 2\n",
      "petal_width>1.75 and sepal_width<=3.1 ; label: 2\n",
      "petal_width>1.75 ; label: 2\n"
     ]
    }
   ],
   "source": [
    "prune_tree = Tree(iris_train_data, 'label')\n",
    "root_prune_tree = prune_tree.make_tree()\n",
    "prune_tree.print_tree(root_prune_tree, 0, 2)\n",
    "pruned_rules = prune_tree.rule_post_pruning(iris_test_data)\n",
    "for pruned_rule in pruned_rules:\n",
    "    print(pruned_rule[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|--(<=2.45)-->{class : 0}\n",
      "|--(>2.45)-->petal_width\n",
      "|            |--(<=1.75)-->sepal_length\n",
      "|            |            |--(<=7.1)-->{class : 1}\n",
      "|            |            |--(>7.1)-->{class : 2}\n",
      "|            |--(>1.75)-->sepal_length\n",
      "|            |            |--(<=5.9)-->sepal_width\n",
      "|            |            |            |--(<=3.1)-->{class : 2}\n",
      "|            |            |            |--(>3.1)-->{class : 1}\n",
      "|            |            |--(>5.9)-->{class : 2}\n"
     ]
    }
   ],
   "source": [
    "prune_tree.post_pruning(iris_test_data)\n",
    "prune_tree.print_tree(root_prune_tree, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|--(<=2.45)-->{class : 0}\n",
      "|--(>2.45)-->petal_width\n",
      "|            |--(<=1.7)-->sepal_length\n",
      "|            |            |--(<=7.1)-->sepal_width\n",
      "|            |            |            |--(<=2.8)-->{class : 1}\n",
      "|            |            |            |--(>2.8)-->{class : 1}\n",
      "|            |            |--(>7.1)-->{class : 2}\n",
      "|            |--(>1.7)-->sepal_length\n",
      "|            |            |--(<=5.9)-->sepal_width\n",
      "|            |            |            |--(<=3.1)-->{class : 2}\n",
      "|            |            |            |--(>3.1)-->{class : 1}\n",
      "|            |            |--(>5.9)-->{class : 2}\n",
      "-------predict-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 2, 2, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_iris = Tree(iris_data, 'label')\n",
    "root_iris = tree_iris.make_tree()\n",
    "tree_iris.print_tree(root_iris, 0, 2)\n",
    "\n",
    "test_data = iris_data.sort_values(by='sepal_width').tail(10)\n",
    "tree_iris.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|--(<=2.45)-->{class : 0}\n",
      "|--(>2.45)-->petal_width\n",
      "|            |--(<=1.75)-->sepal_length\n",
      "|            |            |--(<=7.1)-->sepal_width\n",
      "|            |            |            |--(<=2.2)-->{class : 1}\n",
      "|            |            |            |--(>2.2)-->{class : 1}\n",
      "|            |            |--(>7.1)-->{class : 2}\n",
      "|            |--(>1.75)-->sepal_length\n",
      "|            |            |--(<=5.9)-->sepal_width\n",
      "|            |            |            |--(<=3.1)-->{class : 2}\n",
      "|            |            |            |--(>3.1)-->{class : 1}\n",
      "|            |            |--(>5.9)-->{class : 2}\n",
      "-------rules-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('sepal_length<=5.9 and sepal_width>3.1 ; label: 1', 0.0),\n",
       " ('petal_length>2.45 and petal_width<=1.75 ; label: 1', 0.9166666666666666),\n",
       " ('petal_length<=2.45 ; label: 0', 1.0),\n",
       " ('sepal_length<=7.1 and sepal_width<=2.2 ; label: 1', 1.0),\n",
       " ('sepal_length>7.1 ; label: 2', 1.0),\n",
       " ('petal_width>1.75 and sepal_width<=3.1 ; label: 2', 1.0),\n",
       " ('petal_width>1.75 ; label: 2', 1.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_tree = Tree(iris_train_data, 'label')\n",
    "root_prune_tree = prune_tree.make_tree()\n",
    "prune_tree.print_tree(root_prune_tree, 0, 2)\n",
    "prune_tree.rule_post_pruning(iris_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "outlook\n",
      "|--(Sunny)-->temp\n",
      "|            |--(Hot)-->{class : No}\n",
      "|            |--(Mild)-->{class : No}\n",
      "|            |--(Cool)-->{class : Yes}\n",
      "|--(Overcast)-->{class : Yes}\n",
      "|--(Rain)-->wind\n",
      "|            |--(Weak)-->{class : Yes}\n",
      "|            |--(Strong)-->{class : No}\n",
      "-------tree-------\n",
      "outlook\n",
      "|--(Sunny)-->{class : No}\n",
      "|--(Overcast)-->{class : Yes}\n",
      "|--(Rain)-->wind\n",
      "|            |--(Weak)-->{class : Yes}\n",
      "|            |--(Strong)-->{class : No}\n"
     ]
    }
   ],
   "source": [
    "data_X = data.drop('day', axis=1)\n",
    "training_data1=data_X.iloc[:10]\n",
    "training_data2=data_X.iloc[11]\n",
    "training_data=training_data1.append(training_data2)\n",
    "validate_data=data_X.iloc[[10,12,13]]\n",
    "tree = Tree(training_data, 'play', use_info_gain=True)\n",
    "root = tree.make_tree()\n",
    "\n",
    "tree.print_tree(root, 0, 2)\n",
    "#print(tree.predict(data_X.tail(4)))\n",
    "tree.post_pruning(validate_data)\n",
    "tree.print_tree(root, 0, 2)\n",
    "#print(tree.predict(data_X.tail(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hitung entropi total dataset\n",
    "def total_entropy(data):\n",
    "    proportion = data['play'].value_counts()/len(data)\n",
    "    entropy = 0\n",
    "    for p in proportion.tolist():\n",
    "        entropy -= p*math.log(p,2)\n",
    "    return entropy\n",
    "\n",
    "#hitung information gain dari suatu kolom\n",
    "def gain(data, kolom):\n",
    "    data_entropy = total_entropy(data)\n",
    "    print('KOLOM:', kolom.upper())\n",
    "    print('total entropy of current data', '=',data_entropy)\n",
    "    proportion_kolom = data[kolom].value_counts()/len(data)\n",
    "    sum_entropy_kolom = 0\n",
    "    for value_kolom, value_proportion in zip(proportion_kolom.index.tolist(), proportion_kolom.tolist()):\n",
    "        entropy_value_kolom = total_entropy(data[data[kolom] == value_kolom])\n",
    "        sum_entropy_kolom -= value_proportion*entropy_value_kolom\n",
    "        print('value entropy kolom for', kolom, ':', value_kolom, ':', value_proportion, '=', entropy_value_kolom )\n",
    "    print('sum entropy kolom for', kolom, '=', sum_entropy_kolom)\n",
    "    return data_entropy + sum_entropy_kolom\n",
    "\n",
    "#get current_data\n",
    "def get_node_data(data, kolom, value):\n",
    "    new_data = data[data[kolom] == value]\n",
    "    return new_data.drop(kolom, axis=1)\n",
    "\n",
    "#get current_columns\n",
    "def get_current_columns(data):\n",
    "    return data.drop('play', axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = data\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['play'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root = Ada Hangout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(data, 'ada hangout', 'ya')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(data, 'ada hangout', 'tidak')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = urgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'urgent')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = dekat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'dekat')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = tidak ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'tidak ada')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = dekat ^ malas = tidak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'dekat'), 'malas', 'tidak')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = dekat ^ malas = ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'dekat'), 'malas', 'ya')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
