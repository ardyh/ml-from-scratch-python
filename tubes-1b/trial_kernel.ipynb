{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation - ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements:\n",
    "\n",
    "#### Diturunkan Sendiri:\n",
    "- Program bisa membuat sebuah objek pohon yang bisa menyimpan attributes dari tree (v)\n",
    "- Objek pohon dapat membuat decision tree dari data yang diberikan, dan menyimpan atribut-atribut dari pohon tersebut (v)\n",
    "- Objek pohon dapat menyimpan node-node yang merupakan splitting points untuk membuat keputusan (v)\n",
    "- Objek pohon dapat mengakses seluruh node yang ada pada pohon\n",
    "- Objek pohon dapat memilih splitting point untuk tiap keadaan; apakah menggunakan metrik information gain atau gain ratio (v)\n",
    "- Objek pohon dapat mempertimbangkan atribut yang value-nya continuous dan diskrit (v)\n",
    "- Objek pohon dapat mempertimbangkan atribut yang mempunyai missing value (v)\n",
    "- Objek pohon dapat melakukan post-pruning dengan menggunakan 20% data untuk validasi. Detil pruning kurang lebih: https://www.quora.com/How-can-I-find-a-real-step-by-step-example-of-a-decision-tree-pruning-to-overcome-overfitting\n",
    "- Objek pohon dapat menampilkan pohon yang dibuat\n",
    "- Objek node dapat melakukan splitting pada dataset (menentukan keputusan harus ke node mana setelah suatu kondisi)\n",
    "    - Objek node tahu harus melakukan splitting pada atribut apa\n",
    "    - Objek node menyimpan splitting points pada atribut yang bersangkutan\n",
    "\n",
    "#### Dari Spek:\n",
    "- Overfitting training data dengan post pruning. Gunakanlah 20% training data untuk data validasi.\n",
    "- Continuous-valued attribute: information gain dari kandidate. (v)\n",
    "- Alternative measures for selecting attributes: gain ratio. (v)\n",
    "- Handling missing attribute value: most common target value. (v)\n",
    "- full-training the data \n",
    "- menampilkan modelnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n",
      "0.6428571428571429\n",
      "0.35714285714285715\n",
      "Empty DataFrame\n",
      "Columns: [day, outlook, temp, humidity, wind, play]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"play_tennis.csv\")\n",
    "data.head()\n",
    "proportion = data['play'].value_counts()/len(data)\n",
    "print(proportion[0])\n",
    "entropy = 0\n",
    "for p in proportion.tolist():\n",
    "    print(p)\n",
    "    entropy -= p*math.log(p,2)\n",
    "    \n",
    "print(data[data['outlook'] == 'sunny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read iris data\n",
    "load, target = load_iris(return_X_y=True)\n",
    "iris_data = pd.DataFrame(load, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "iris_data['label'] = pd.Series(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisi kelas Node\n",
    "#Node merupakan split point pada tree. \n",
    "#Kelas ini menyimpan data yang ada pada suatu split point, atribut apa yang digunakan untuk splitting, dan tipe atribut tsb. Atau jika node merupakan daun maka disimpan value-nya\n",
    "#Kelas ini dapat menentukan splitting point kebawah dari suatu node, baik atribut splittingnya kontinu maupun diskrit\n",
    "#Atribut-atribut Node: \n",
    "# - data: subset data\n",
    "# - split_attr: nama atribut yang akan di split\n",
    "# - split_values: value cabang dari node (merupakan satu integer jika continuous, dan multiple values jika categorical)\n",
    "# - target_attr: atribut label/atribut target prediksi\n",
    "# - attr_cont_split: splitting point dari atribut tsb (jika atribut tsb kontinu)\n",
    "# - is_leaf: apakah node merupakan daun atau tidak\n",
    "# - leaf_value: nilai hasil prediksi jika node merupakan daun\n",
    "# - childs: anak dari node yang berupa node\n",
    "class Node:\n",
    "    #konstruktor\n",
    "    def __init__(self, data, split_attr, target_attr, is_continuous=False, split_value_continuous=None, is_leaf=False, leaf_value=None, parent_value=None):\n",
    "        self.data = data\n",
    "        self.split_attr = split_attr\n",
    "        self.target_attr = target_attr\n",
    "        self.childs = []\n",
    "        self.is_leaf = is_leaf\n",
    "        self.split_values = [split_value_continuous]\n",
    "        self.leaf_value = leaf_value\n",
    "        self.parent_value = parent_value\n",
    "\n",
    "    #check apakah split attribute == numerik\n",
    "    def is_attr_categorical(self):\n",
    "        return self.data[self.split_attr].dtype == 'O'\n",
    "    \n",
    "    #get splits node jika node bukan daun\n",
    "    def get_splits(self):\n",
    "        if( not self.check_if_leaf()):\n",
    "            #jika atribut split categorical\n",
    "            if(self.is_attr_categorical()):\n",
    "                #tentukan split values\n",
    "                self.split_values = self.data[self.split_attr].unique()\n",
    "            #jika atribut numerik / continuous, split value sudah didefinisikan sejak konstruksi objek\n",
    "            return self.split_values\n",
    "                        \n",
    "    #add a child to a node\n",
    "    def add_child(self, node):\n",
    "        self.childs.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisi kelas Tree\n",
    "#Kelas ini mengkonstruksi decision tree dengan menghubungkan sekumpulan node, juga memilih untuk tiap node \n",
    "#atribut apa yang akan digunakan untuk splitting. Kelas ini dapat mempertimbangkan atribut yang mengandung nilai null.\n",
    "#Metrik yang  digunakan bisa dipilih antara information gain atau gain ratio.\n",
    "#Kelas ini dapat melakukan pruning pada tree yang dibuat, dan juga dapat mencetak model tree yang telah dibuat\n",
    "#NOTE: Asumsi missing value, bernilai \"None\" atau \"none\"\n",
    "#Atribut-atribut Tree:\n",
    "# - data: merupakan data yang digunakan untuk training\n",
    "# - target_attr: atribut yang menjadi target prediksi (label)\n",
    "# - root: node yang merupakan root\n",
    "# - use_info_gain: True/False. Jika true maka metrik pemilihan atribut menggunakan information gain. Jika False, metrik menggunakan gain ratio\n",
    "class Tree:\n",
    "    #konstruktor\n",
    "    def __init__(self, data, target_attr, use_info_gain=True,root_value=None):\n",
    "        self.data = data\n",
    "        self.target_attr = target_attr\n",
    "        self.root = None\n",
    "        self.root_value = root_value\n",
    "        self.use_info_gain = use_info_gain\n",
    "        self.ruleset = []\n",
    "    \n",
    "    #cari entropi total pada data\n",
    "    def total_entropy(self, data):\n",
    "        proportion = data[self.target_attr].value_counts()/len(data)\n",
    "        entropy = 0\n",
    "        for p in proportion.tolist():\n",
    "            entropy -= p*math.log(p,2)\n",
    "        return entropy\n",
    "    \n",
    "    #hitung information gain dari suatu kolom\n",
    "    def info_gain(self, kolom):\n",
    "        data = self.data\n",
    "        data_entropy = self.total_entropy(data)\n",
    "        proportion_kolom = data[kolom].value_counts()/len(data)\n",
    "        sum_entropy_kolom = 0\n",
    "        for value_kolom, value_proportion in zip(proportion_kolom.index.tolist(), proportion_kolom.tolist()):\n",
    "            #print(\"here checking\")\n",
    "            #print(data[data[kolom] == value_kolom])\n",
    "            entropy_value_kolom = self.total_entropy(data[data[kolom] == value_kolom])\n",
    "            sum_entropy_kolom -= value_proportion*entropy_value_kolom\n",
    "            \n",
    "        return data_entropy + sum_entropy_kolom\n",
    "    \n",
    "    #hitung information split pada data di suatu atribut\n",
    "    def split_info(self, attr):\n",
    "        proportion = self.data[attr].value_counts()/len(data)\n",
    "        split_info = 0\n",
    "        for p in proportion.tolist():\n",
    "            split_info -= p*math.log(p,2)\n",
    "        return split_info\n",
    "    \n",
    "    #hitung gain ratio untuk suatu atribut\n",
    "    def gain_ratio(self, attr):\n",
    "        return info_gain(attr)/split_info(attr)\n",
    "    \n",
    "    #cari split-split yang memungkinkan pada atribut continuous\n",
    "    def find_possible_splits_continuous(self, sorted_data, split_attr):\n",
    "        sorted_target = sorted_data[self.target_attr].values.tolist()\n",
    "        sorted_attr = sorted_data[split_attr].values.tolist()\n",
    "        prev_target_value = sorted_target[0]\n",
    "        possible_splits = []\n",
    "        #iterasi target value, cari titik-titik dimana \n",
    "        try:\n",
    "            for i in range(1, len(sorted_target)):\n",
    "                el = sorted_target[i]\n",
    "                if (prev_target_value != el):\n",
    "                    possible_splits.append(0.5*(sorted_attr[i] + sorted_attr[i-1]))\n",
    "                prev_target_value = el\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            return possible_splits\n",
    "    \n",
    "    #cari gain dari tiap split dan cari split optimum\n",
    "    def find_optimum_split_continuous(self, pos_splits, sorted_data, split_attr):\n",
    "        optimum_split = 0\n",
    "        max_info_gain = -1\n",
    "        #iterate split\n",
    "        for i, el in enumerate(pos_splits):\n",
    "            #hitung information gain\n",
    "            current_gain = self.calculate_info_gain_continuous(el, sorted_data, split_attr)\n",
    "            #jika information gain lebih dari sebelumnya, ganti optimum split\n",
    "            if(current_gain > max_info_gain):\n",
    "                max_info_gain = current_gain\n",
    "                optimum_split = el\n",
    "        return optimum_split\n",
    "    \n",
    "    #cari information gain pada suatu split continuous\n",
    "    def calculate_info_gain_continuous(self, split_value, sorted_data, split_attr):\n",
    "        data_entropy = self.total_entropy(sorted_data)\n",
    "        #pisah data mjd \"<=\" dan \">\" split_value\n",
    "        data_less_than_equal = sorted_data[sorted_data[split_attr] <= split_value]\n",
    "        data_more_than = sorted_data[sorted_data[split_attr] > split_value]\n",
    "        #hitung entropi kolom\n",
    "        entropy_less_than_equal = (float(len(data_less_than_equal))/len(sorted_data)) * self.total_entropy(data_less_than_equal)\n",
    "        entropy_more_than = (float(len(data_more_than))/len(sorted_data)) * self.total_entropy(data_more_than)\n",
    "        return data_entropy - entropy_less_than_equal - entropy_more_than\n",
    "    \n",
    "    #check apakah attribute == numerik\n",
    "    def is_attr_categorical(self, attr):\n",
    "        return self.data[attr].dtype == 'O'\n",
    "    \n",
    "    #handling missing value\n",
    "    def handle_missing_value(self, split_attr):\n",
    "        if(self.is_attr_categorical(split_attr)):\n",
    "            mode = self.data[split_attr].mode().values[0]\n",
    "            self.data[split_attr] = self.data[split_attr].replace({None:mode})        \n",
    "    \n",
    "    #buat tree\n",
    "    def make_tree(self):\n",
    "        #cari info_gain dari masing-masing kolom \n",
    "        data_X = self.data.drop(self.target_attr, axis=1)\n",
    "        \n",
    "        #basis-1: jika data terbagi dg sempurna\n",
    "        if(self.data[self.target_attr].nunique() == 1):\n",
    "            self.root = Node(\"none\", \"none\", \"none\", is_leaf=True, leaf_value=self.data[self.target_attr].unique()[0], parent_value=self.root_value)\n",
    "            return self.root\n",
    "        \n",
    "        #basis-2: jika tidak ada atribut\n",
    "        if(len(data_X.columns) == 0):\n",
    "            self.root = Node(\"none\", \"none\", \"none\", is_leaf=True, leaf_value=self.data[self.target_attr].mode().values[0], parent_value=self.root_value)\n",
    "            return self.root\n",
    "        \n",
    "        #rekurens, jika data tidak bisa mjd leaf\n",
    "        else:\n",
    "            max_metric = -1\n",
    "            split_attr = \"\"\n",
    "            is_split_attr_categorical = True\n",
    "            for attr in data_X.columns:\n",
    "                #Jika kolom kategorikal\n",
    "                if(self.is_attr_categorical(attr)):\n",
    "                    if(self.use_info_gain):\n",
    "                        current_metric = self.info_gain(attr)\n",
    "                    else:\n",
    "                        current_metric = self.gain_ratio(attr)\n",
    "                #jika kolom numerik\n",
    "                else:\n",
    "                    #sort data\n",
    "                    sorted_data = self.data.sort_values(by=attr)\n",
    "                    #cari split-split yang memungkinkan \n",
    "                    pos_splits = self.find_possible_splits_continuous(sorted_data, attr)\n",
    "                    #hitung gain dari tiap continuous split dan cari nilai optimum\n",
    "                    split_value_continuous = self.find_optimum_split_continuous(pos_splits, sorted_data, attr)\n",
    "                    #hitung gain ketika sudah diketahui nilai optimum\n",
    "                    current_metric = self.calculate_info_gain_continuous(split_value_continuous, sorted_data, attr)\n",
    "\n",
    "                #jika ditemukan maximum info gain di kolom tertentu\n",
    "                if(current_metric > max_metric):\n",
    "                    max_metric = current_metric\n",
    "                    split_attr = attr\n",
    "                    is_split_attr_categorical = self.is_attr_categorical(attr)\n",
    "                    if (not is_split_attr_categorical):\n",
    "                        split_value_attr = split_value_continuous\n",
    "            \n",
    "            #setelah atribut dipilih, cek apakah ada missing value\n",
    "            #impute missing value dengan modus pada atribut tsb. (asumsi: atribut yg di handle hanyalah kategorikal)\n",
    "            self.handle_missing_value(split_attr)\n",
    "            \n",
    "            #buat node\n",
    "            #jika atribut terpilih == kategorikal\n",
    "            if(is_split_attr_categorical):\n",
    "                self.root = Node(self.data, split_attr, self.target_attr, parent_value=self.root_value)\n",
    "                split_values = self.data[split_attr].unique()\n",
    "                #iterate all split values\n",
    "                for split_value in split_values:\n",
    "                    filtered_data = self.data[self.data[split_attr] == split_value].drop(split_attr, axis=1)\n",
    "                    self.root.add_child(Tree(filtered_data, self.target_attr, root_value=split_value).make_tree())\n",
    "\n",
    "            #jika atribut terpilih == numerik & kontinu\n",
    "            else:\n",
    "                self.root = Node(self.data, split_attr, self.target_attr, is_continuous=True, split_value_continuous=split_value_attr, parent_value=self.root_value)\n",
    "                #filter <=\n",
    "                filtered_data = self.data[self.data[split_attr] <= split_value_attr].drop(split_attr, axis=1)\n",
    "                self.root.add_child(Tree(filtered_data, self.target_attr, root_value=\"<=\"+str(split_value_attr)).make_tree())\n",
    "\n",
    "                #filter >\n",
    "                filtered_data = self.data[self.data[split_attr] > split_value_attr].drop(split_attr, axis=1)\n",
    "                self.root.add_child(Tree(filtered_data, self.target_attr, root_value=\">\"+str(split_value_attr)).make_tree())\n",
    "\n",
    "            return self.root\n",
    "\n",
    "    def print_tree(self, node, depth, space):\n",
    "        if (depth == 0):\n",
    "            print('-------tree-------')\n",
    "            dash = ''\n",
    "        else:\n",
    "            dash = '|' + '-'*space + '>'\n",
    "            \n",
    "        if(node.is_leaf):\n",
    "            output = ('|' + (' '*space))*(depth-1) + dash + '{' + str(node.leaf_value) + '}'\n",
    "        else:\n",
    "            output = ('|' + (' '*space))*(depth-1) + dash + node.split_attr \n",
    "        \n",
    "        if (node.parent_value):\n",
    "            output = output + '    (' + node.parent_value + ')'\n",
    "        \n",
    "        print(output)\n",
    "        \n",
    "        depth += 1\n",
    "        for child in node.childs:\n",
    "            self.print_tree(child, depth, space)\n",
    "            \n",
    "    #bagian rekursif untuk prediksi\n",
    "    def get_prediction_result(self, prediction_instance, node):\n",
    "        #basis - jika node merupakan leaf, kembalikan value\n",
    "        if(node.is_leaf):\n",
    "            return node.leaf_value\n",
    "        \n",
    "        #rekurens - jika node bukan leaf, cari anaknya yang tepat, telusuri anak\n",
    "        else:\n",
    "            #jika node categorical\n",
    "            if(node.is_attr_categorical()):\n",
    "                for child in node.childs:\n",
    "                    if (child.parent_value == prediction_instance[node.split_attr]):\n",
    "                        return self.get_prediction_result(prediction_instance, child)\n",
    "                        break\n",
    "            #jika node numerik/kontinu\n",
    "            else:\n",
    "                if(prediction_instance[node.split_attr] <= node.split_values[0]):\n",
    "                    return self.get_prediction_result(prediction_instance, node.childs[0])\n",
    "                elif(prediction_instance[node.split_attr] > node.split_values[0]):\n",
    "                    return self.get_prediction_result(prediction_instance, node.childs[1])\n",
    "                \n",
    "    #prediksi suatu dataset test\n",
    "    def predict(self, test_data):\n",
    "        print('-------predict-------')\n",
    "        pred_result = []\n",
    "        #iterasi seluruh instance pada test_data\n",
    "        for i in range(len(test_data)):\n",
    "            #instance untuk di prediksi\n",
    "            prediction_instance = test_data.iloc[i]\n",
    "            #get prediction untuk instance yang dicek, lalu append ke hasil\n",
    "            pred_result.append(self.get_prediction_result(prediction_instance, self.root))\n",
    "        return pred_result\n",
    "    \n",
    "    #transformasi tree menjadi kumpulan rule\n",
    "    def recursively_write_rule(self, node, rule):\n",
    "        #basis - mencapai leaf. Append rule ke ruleset\n",
    "        if(node.is_leaf):\n",
    "            new_rule = rule + [[self.target_attr, node.leaf_value]]\n",
    "            self.ruleset.append(new_rule)\n",
    "        \n",
    "        #rekurens - mencatat current precondition dan telusuri anak-anaknya\n",
    "        else:\n",
    "            for child in node.childs:\n",
    "                new_rule = rule + [[node.split_attr, child.parent_value]]\n",
    "                self.recursively_write_rule(child, new_rule)\n",
    "    \n",
    "    #parsing rule menjadi query\n",
    "    def parse_rule(self, rule):\n",
    "        str_rule = ''\n",
    "        for statement in rule[:-1]:\n",
    "            #categorical variable\n",
    "            if (statement[1][0] != \"<\") and (statement[1][0] != \">\"):\n",
    "                str_rule += statement[0] + ' == \"' + statement[1] + '\" and '\n",
    "            else:\n",
    "                str_rule += statement[0] + statement[1] + ' and '\n",
    "        return str_rule[:-4]\n",
    "    \n",
    "    #kalkulasi akurasi suatu rule\n",
    "    def calculate_rule_accuracy(self, rule):\n",
    "        query = self.parse_rule(rule)\n",
    "        filtered_data = self.data_test.query(query)\n",
    "        target_value = rule[-1][1]\n",
    "        num_correct_answers = len(filtered_data[filtered_data[self.target_attr] == target_value])\n",
    "        if(len(filtered_data) == 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return float(num_correct_answers)/float(len(filtered_data))\n",
    "    \n",
    "    #pruning untuk suatu rule\n",
    "    def prune_rule(self, rule, prev_accuracy):\n",
    "        if(len(rule) > 2):\n",
    "            optimal_rule = []\n",
    "            max_accuracy = -1\n",
    "            for statement in rule[:-1]:\n",
    "                temp_rule = rule.copy()\n",
    "                temp_rule.remove(statement)\n",
    "                accuracy = self.calculate_rule_accuracy(temp_rule)\n",
    "                if accuracy > max_accuracy:\n",
    "                    max_accuracy = accuracy\n",
    "                    optimal_rule = temp_rule\n",
    "\n",
    "            #basis - akurasi tidak improve\n",
    "            if((max_accuracy <= prev_accuracy) or (len(rule) == 0)):\n",
    "                return (optimal_rule, rule[-1][-1], max_accuracy)\n",
    "            #rekurens - akurasi masih bisa dinaikkan dengan pruning\n",
    "            else:\n",
    "                return self.prune_rule(optimal_rule, max_accuracy)\n",
    "        else:\n",
    "            return (rule, rule[-1][-1], self.calculate_rule_accuracy(rule))\n",
    "    \n",
    "    #post-pruning\n",
    "    def rule_post_pruning(self, data_test):\n",
    "        print('-------rules-------')\n",
    "        #definisikan rules yang ada\n",
    "        #lakukan DFS pada tree sampai leaf. Catat semua rule yang ada\n",
    "        self.recursively_write_rule(self.root, [])\n",
    "        \n",
    "        #set data test\n",
    "        self.data_test = data_test\n",
    "        \n",
    "        #prune rule\n",
    "        sorted_rule = {}\n",
    "        for i, rule in enumerate(self.ruleset):\n",
    "            pruned_rule, label, accuracy = (self.prune_rule(rule, -1))\n",
    "            sorted_rule[self.parse_rule(pruned_rule)+'; label: '+str(label)] = accuracy\n",
    "\n",
    "        sorted_rule = sorted(sorted_rule.items(), key=lambda kv: kv[1])\n",
    "        return sorted_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|-->{0}    (<=2.45)\n",
      "|-->petal_width    (>2.45)\n",
      "|  |-->sepal_length    (<=1.7)\n",
      "|  |  |-->{2}    (<=4.95)\n",
      "|  |  |-->sepal_width    (>4.95)\n",
      "|  |  |  |-->{1}    (<=2.2)\n",
      "|  |  |  |-->{1}    (>2.2)\n",
      "|  |-->sepal_length    (>1.7)\n",
      "|  |  |-->sepal_width    (<=5.9)\n",
      "|  |  |  |-->{2}    (<=3.1)\n",
      "|  |  |  |-->{1}    (>3.1)\n",
      "|  |  |-->{2}    (>5.9)\n",
      "-------rules-------\n",
      "sepal_length<=5.9 and sepal_width>3.1 ; label: 1\n",
      "petal_length>2.45 ; label: 2\n",
      "petal_length>2.45 ; label: 1\n",
      "petal_length<=2.45 ; label: 0\n",
      "sepal_length>4.95 and sepal_width<=2.2 ; label: 1\n",
      "petal_width>1.7 and sepal_width<=3.1 ; label: 2\n",
      "petal_width>1.7 ; label: 2\n"
     ]
    }
   ],
   "source": [
    "prune_tree = Tree(iris_train_data, 'label')\n",
    "root_prune_tree = prune_tree.make_tree()\n",
    "prune_tree.print_tree(root_prune_tree, 0, 2)\n",
    "pruned_rules = prune_tree.rule_post_pruning(iris_test_data)\n",
    "for pruned_rule in pruned_rules:\n",
    "    print(pruned_rule[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|-->{0}    (<=2.45)\n",
      "|-->petal_width    (>2.45)\n",
      "|  |-->sepal_length    (<=1.7)\n",
      "|  |  |-->sepal_width    (<=7.1)\n",
      "|  |  |  |-->{1}    (<=2.8)\n",
      "|  |  |  |-->{1}    (>2.8)\n",
      "|  |  |-->{2}    (>7.1)\n",
      "|  |-->sepal_length    (>1.7)\n",
      "|  |  |-->sepal_width    (<=5.9)\n",
      "|  |  |  |-->{2}    (<=3.1)\n",
      "|  |  |  |-->{1}    (>3.1)\n",
      "|  |  |-->{2}    (>5.9)\n",
      "-------predict-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 2, 2, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_iris = Tree(iris_data, 'label')\n",
    "root_iris = tree_iris.make_tree()\n",
    "tree_iris.print_tree(root_iris, 0, 2)\n",
    "\n",
    "test_data = iris_data.sort_values(by='sepal_width').tail(10)\n",
    "tree_iris.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_iris_data = iris_data.sample(frac=1).reset_index().drop('index', axis=1)\n",
    "iris_train_data = randomized_iris_data.iloc[0:120]\n",
    "iris_test_data = randomized_iris_data.iloc[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "petal_length\n",
      "|-->{0}    (<=2.45)\n",
      "|-->petal_width    (>2.45)\n",
      "|  |-->sepal_length    (<=1.7)\n",
      "|  |  |-->{2}    (<=4.95)\n",
      "|  |  |-->sepal_width    (>4.95)\n",
      "|  |  |  |-->{1}    (<=2.2)\n",
      "|  |  |  |-->{1}    (>2.2)\n",
      "|  |-->sepal_length    (>1.7)\n",
      "|  |  |-->sepal_width    (<=5.9)\n",
      "|  |  |  |-->{2}    (<=3.1)\n",
      "|  |  |  |-->{1}    (>3.1)\n",
      "|  |  |-->{2}    (>5.9)\n",
      "-------rules-------\n",
      "petal_length\n",
      "none\n",
      "petal_width\n",
      "sepal_length\n",
      "none\n",
      "sepal_width\n",
      "none\n",
      "none\n",
      "sepal_length\n",
      "sepal_width\n",
      "none\n",
      "none\n",
      "none\n",
      "[['petal_length', '<=2.45'], ['none', 0]]\n",
      "[['petal_length', '>2.45'], ['petal_width', '<=1.7'], ['sepal_length', '<=4.95'], ['none', 2]]\n",
      "[['petal_length', '>2.45'], ['petal_width', '<=1.7'], ['sepal_length', '>4.95'], ['sepal_width', '<=2.2'], ['none', 1]]\n",
      "[['petal_length', '>2.45'], ['petal_width', '<=1.7'], ['sepal_length', '>4.95'], ['sepal_width', '>2.2'], ['none', 1]]\n",
      "[['petal_length', '>2.45'], ['petal_width', '>1.7'], ['sepal_length', '<=5.9'], ['sepal_width', '<=3.1'], ['none', 2]]\n",
      "[['petal_length', '>2.45'], ['petal_width', '>1.7'], ['sepal_length', '<=5.9'], ['sepal_width', '>3.1'], ['none', 1]]\n",
      "[['petal_length', '>2.45'], ['petal_width', '>1.7'], ['sepal_length', '>5.9'], ['none', 2]]\n",
      "rule: [['none', 0]]\n",
      "query: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expr cannot be an empty string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-24becdc5fd0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mroot_prune_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprune_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprune_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_prune_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprune_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrule_post_pruning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris_test_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-107-80cc12214bbd>\u001b[0m in \u001b[0;36mrule_post_pruning\u001b[1;34m(self, data_test)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0msorted_rule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruleset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mpruned_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprune_rule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[0msorted_rule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpruned_rule\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-80cc12214bbd>\u001b[0m in \u001b[0;36mprune_rule\u001b[1;34m(self, rule, prev_accuracy)\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mtemp_rule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mtemp_rule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_rule_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                 \u001b[0mmax_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-80cc12214bbd>\u001b[0m in \u001b[0;36mcalculate_rule_accuracy\u001b[1;34m(self, rule)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rule:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'query:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0mfiltered_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[0mtarget_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mnum_correct_answers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   3086\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3087\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3088\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3090\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   3201\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3202\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'resolvers'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resolvers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0m_check_expression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mexprs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\eval.py\u001b[0m in \u001b[0;36m_check_expression\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expr cannot be an empty string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expr cannot be an empty string"
     ]
    }
   ],
   "source": [
    "prune_tree = Tree(iris_train_data, 'label')\n",
    "root_prune_tree = prune_tree.make_tree()\n",
    "prune_tree.print_tree(root_prune_tree, 0, 2)\n",
    "prune_tree.rule_post_pruning(iris_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------tree-------\n",
      "outlook\n",
      "|-->humidity    (Sunny)\n",
      "|  |-->{No}    (High)\n",
      "|  |-->{Yes}    (Normal)\n",
      "|-->{Yes}    (Overcast)\n",
      "|-->wind    (Rain)\n",
      "|  |-->{Yes}    (Weak)\n",
      "|  |-->{No}    (Strong)\n",
      "-------predict-------\n",
      "-------predict-------\n",
      "['Yes', 'Yes', 'Yes', 'No']\n"
     ]
    }
   ],
   "source": [
    "data_X = data.drop('day', axis=1)\n",
    "tree = Tree(data_X, 'play', use_info_gain=True)\n",
    "root = tree.make_tree()\n",
    "\n",
    "tree.print_tree(root, 0, 2)\n",
    "print('-------predict-------')\n",
    "print(tree.predict(data_X.tail(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hitung entropi total dataset\n",
    "def total_entropy(data):\n",
    "    proportion = data['play'].value_counts()/len(data)\n",
    "    entropy = 0\n",
    "    for p in proportion.tolist():\n",
    "        entropy -= p*math.log(p,2)\n",
    "    return entropy\n",
    "\n",
    "#hitung information gain dari suatu kolom\n",
    "def gain(data, kolom):\n",
    "    data_entropy = total_entropy(data)\n",
    "    print('KOLOM:', kolom.upper())\n",
    "    print('total entropy of current data', '=',data_entropy)\n",
    "    proportion_kolom = data[kolom].value_counts()/len(data)\n",
    "    sum_entropy_kolom = 0\n",
    "    for value_kolom, value_proportion in zip(proportion_kolom.index.tolist(), proportion_kolom.tolist()):\n",
    "        entropy_value_kolom = total_entropy(data[data[kolom] == value_kolom])\n",
    "        sum_entropy_kolom -= value_proportion*entropy_value_kolom\n",
    "        print('value entropy kolom for', kolom, ':', value_kolom, ':', value_proportion, '=', entropy_value_kolom )\n",
    "    print('sum entropy kolom for', kolom, '=', sum_entropy_kolom)\n",
    "    return data_entropy + sum_entropy_kolom\n",
    "\n",
    "#get current_data\n",
    "def get_node_data(data, kolom, value):\n",
    "    new_data = data[data[kolom] == value]\n",
    "    return new_data.drop(kolom, axis=1)\n",
    "\n",
    "#get current_columns\n",
    "def get_current_columns(data):\n",
    "    return data.drop('play', axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOLOM: DAY\n",
      "total entropy of current data = 0.9402859586706309\n",
      "value entropy kolom for day : D7 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D6 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D12 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D13 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D10 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D8 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D14 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D5 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D3 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D4 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D1 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D9 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D2 : 0.07142857142857142 = 0.0\n",
      "value entropy kolom for day : D11 : 0.07142857142857142 = 0.0\n",
      "sum entropy kolom for day = 0.0\n",
      "gain day : 0.9402859586706309\n",
      "KOLOM: OUTLOOK\n",
      "total entropy of current data = 0.9402859586706309\n",
      "value entropy kolom for outlook : Sunny : 0.35714285714285715 = 0.9709505944546686\n",
      "value entropy kolom for outlook : Rain : 0.35714285714285715 = 0.9709505944546686\n",
      "value entropy kolom for outlook : Overcast : 0.2857142857142857 = 0.0\n",
      "sum entropy kolom for outlook = -0.6935361388961918\n",
      "gain outlook : 0.2467498197744391\n",
      "KOLOM: TEMP\n",
      "total entropy of current data = 0.9402859586706309\n",
      "value entropy kolom for temp : Mild : 0.42857142857142855 = 0.9182958340544896\n",
      "value entropy kolom for temp : Cool : 0.2857142857142857 = 0.8112781244591328\n",
      "value entropy kolom for temp : Hot : 0.2857142857142857 = 1.0\n",
      "sum entropy kolom for temp = -0.9110633930116763\n",
      "gain temp : 0.029222565658954647\n",
      "KOLOM: HUMIDITY\n",
      "total entropy of current data = 0.9402859586706309\n",
      "value entropy kolom for humidity : High : 0.5 = 0.9852281360342516\n",
      "value entropy kolom for humidity : Normal : 0.5 = 0.5916727785823275\n",
      "sum entropy kolom for humidity = -0.7884504573082896\n",
      "gain humidity : 0.15183550136234136\n",
      "KOLOM: WIND\n",
      "total entropy of current data = 0.9402859586706309\n",
      "value entropy kolom for wind : Weak : 0.5714285714285714 = 0.8112781244591328\n",
      "value entropy kolom for wind : Strong : 0.42857142857142855 = 1.0\n",
      "sum entropy kolom for wind = -0.8921589282623617\n",
      "gain wind : 0.04812703040826927\n",
      "GAINS\n",
      " day         0.940286\n",
      "outlook     0.246750\n",
      "temp        0.029223\n",
      "humidity    0.151836\n",
      "wind        0.048127\n",
      "dtype: float64\n",
      "AKTIVITAS TERKAIT ['Yes', 'No']\n"
     ]
    }
   ],
   "source": [
    "current_data = data\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['play'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D6</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D7</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D8</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D9</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D10</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D11</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D12</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D13</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D14</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    day   outlook  temp humidity    wind play\n",
       "0    D1     Sunny   Hot     High    Weak   No\n",
       "1    D2     Sunny   Hot     High  Strong   No\n",
       "2    D3  Overcast   Hot     High    Weak  Yes\n",
       "3    D4      Rain  Mild     High    Weak  Yes\n",
       "4    D5      Rain  Cool   Normal    Weak  Yes\n",
       "5    D6      Rain  Cool   Normal  Strong   No\n",
       "6    D7  Overcast  Cool   Normal  Strong  Yes\n",
       "7    D8     Sunny  Mild     High    Weak   No\n",
       "8    D9     Sunny  Cool   Normal    Weak  Yes\n",
       "9   D10      Rain  Mild   Normal    Weak  Yes\n",
       "10  D11     Sunny  Mild   Normal  Strong  Yes\n",
       "11  D12  Overcast  Mild     High  Strong  Yes\n",
       "12  D13  Overcast   Hot   Normal    Weak  Yes\n",
       "13  D14      Rain  Mild     High  Strong   No"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root = Ada Hangout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ada hangout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ada hangout'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-96e4c7609965>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcurrent_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_node_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ada hangout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ya'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcurrent_gains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkolom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_current_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgain_kolom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkolom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gain\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkolom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain_kolom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-6a93c165fb1d>\u001b[0m in \u001b[0;36mget_node_data\u001b[1;34m(data, kolom, value)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#get current_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_node_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkolom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkolom\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkolom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ada hangout'"
     ]
    }
   ],
   "source": [
    "current_data = get_node_data(data, 'ada hangout', 'ya')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(data, 'ada hangout', 'tidak')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = urgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'urgent')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = dekat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'dekat')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = tidak ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'tidak ada')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterasi 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = dekat ^ malas = tidak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'dekat'), 'malas', 'tidak')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ada hangout = tidak ^ deadline = dekat ^ malas = ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = get_node_data(get_node_data(get_node_data(data, 'ada hangout', 'tidak'), 'deadline', 'dekat'), 'malas', 'ya')\n",
    "current_gains = []\n",
    "for kolom in get_current_columns(current_data):\n",
    "    gain_kolom = gain(current_data, kolom)\n",
    "    print(\"gain\", kolom, \":\", gain_kolom)\n",
    "    current_gains.append([kolom, gain_kolom])\n",
    "current_gains = pd.Series([x[1] for x in current_gains], index=[x[0] for x in current_gains])\n",
    "print('GAINS\\n', current_gains)\n",
    "print('AKTIVITAS TERKAIT', current_data['aktivitas'].value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
